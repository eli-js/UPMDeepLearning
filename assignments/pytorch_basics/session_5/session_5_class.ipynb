{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Deep Learning - Master in Deep Learning of UPM</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sesiÃ³n prÃ¡ctica de Pytorch Lightning aprenderemos:\n",
    "- [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) - Utilidad Ãºnica de Lightning que encapsula todo lo relacionado con el manejo de los datos antes, durante y despuÃ©s del entrenamiento.\n",
    "- [LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) - La pieza bÃ¡sica de Lightning en la que definiremos tanto la arquitectura como el entrenamiento de nuestros modelos.\n",
    "- [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) - MÃ³dulo altamente customizable con el que podremos entrenar y realizar inferencia.\n",
    "- [Callbacks](https://lightning.ai/docs/pytorch/stable/extensions/callbacks.html) - Funciones que se ejecutarÃ¡n cuando determinados eventos a nuestra elecciÃ³n se den.\n",
    "- [Logging](https://lightning.ai/docs/pytorch/stable/extensions/logging.html) - Registro automÃ¡tico de mÃ©tricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**\n",
    "\n",
    "Antes de empezar debemos instalar PyTorch Lightning, por defecto, esto valdrÃ­a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdemÃ¡s, si te encuentras ejecutando este cÃ³digo en Google Collab, lo mejor serÃ¡ que montes tu drive para tener acceso a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado y GestiÃ³n de Datos con Lightning: LightningDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Lightning propone el uso del [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) para el preprocesado y la gestiÃ³n de los diferentes splits.\n",
    "Â¿Es realmente necesario hacer uso de esta herramienta?\n",
    "- Respuesta corta: no.\n",
    "- Respuesta larga (y coherente): no, sin embargo, nos va a ayudar a tener un cÃ³digo mucho mÃ¡s centralizado y lo mÃ¡s importante, **reproducible**.\n",
    "\n",
    "Existen ciertos parÃ¡metros y/o funciones de preprocesamiento que vamos a aplicar a todos los splits de nuestro dataset. El DataModule nos va a otorgar la capacidad de gestionar esto con amplia flexibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo vamos a cargar el dataset de iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "43b43202-3ef3-4ed7-919a-e9d4ea2449fa",
       "rows": [
        [
         "0",
         "5.1",
         "3.5",
         "1.4",
         "0.2",
         "0"
        ],
        [
         "1",
         "4.9",
         "3.0",
         "1.4",
         "0.2",
         "0"
        ],
        [
         "2",
         "4.7",
         "3.2",
         "1.3",
         "0.2",
         "0"
        ],
        [
         "3",
         "4.6",
         "3.1",
         "1.5",
         "0.2",
         "0"
        ],
        [
         "4",
         "5.0",
         "3.6",
         "1.4",
         "0.2",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "IRIS_PATH = 'data/iris.csv'\n",
    "\n",
    "iris_df = pd.read_csv(IRIS_PATH)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaciÃ³n vamos a encapsular este conjunto de datos en un PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2]]),\n",
       " array([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class IrisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        self.labels = self.data['target'].values\n",
    "        self.features = self.data.drop('target', axis=1).values # todas las columnas menos la Ãºltima\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "        target = self.labels[idx]\n",
    "        return features, target\n",
    "\n",
    "iris_df = pd.read_csv(IRIS_PATH) # cargamos el dataset\n",
    "iris_dataset = IrisDataset(iris_df)\n",
    "iris_dataset[0:4] # muestra los 4 primeros elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, crearemos una funciÃ³n que nos divida un DataFrame en train, validaciÃ³n y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_val_test(df, val_size=0.2, test_size=0.2):\n",
    "    eval_size = val_size + test_size # eval es un split intermedio que luego se divide en val y test\n",
    "    test_prop = test_size / eval_size # proporciÃ³n de test respecto a eval\n",
    "\n",
    "    train, eval_ = train_test_split(df, test_size=eval_size)\n",
    "    val, test = train_test_split(eval_, test_size=test_prop)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En PyTorch bÃ¡sico preprocesarÃ­amos y crearÃ­amos los DataLoaders de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features, targets = zip(*batch)\n",
    "    features = torch.tensor(np.stack(features), dtype=torch.float32)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    return features, targets\n",
    "\n",
    "iris_df = pd.read_csv(IRIS_PATH)\n",
    "train_df, val_df, test_df = split_train_val_test(iris_df)\n",
    "\n",
    "iris_train = IrisDataset(train_df)\n",
    "iris_val = IrisDataset(val_df)\n",
    "iris_test = IrisDataset(test_df)\n",
    "\n",
    "iris_train_loader = DataLoader(iris_train, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "iris_val_loader = DataLoader(iris_val, batch_size=16, collate_fn=collate_fn)\n",
    "iris_test_loader = DataLoader(iris_test, batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El equivalente en Lightning es exactamente igual, sin embargo, al estar encapsulado, lo hacemos reusable en otros proyectos.\n",
    "\n",
    "Puede parecer mÃ¡s cÃ³digo, sin embargo, al ser modular, es mucho mÃ¡s fÃ¡cil realizar cambios. AdemÃ¡s desde el mismo objeto tenemos acceso a todos los dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class IrisDataModule(pytorch_lightning.LightningDataModule):\n",
    "    def __init__(self, df, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.train_df, self.val_df, self.test_df = split_train_val_test(df)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self): \n",
    "        \"\"\"\n",
    "        Esta funciÃ³n no es necesaria de implementar\n",
    "        Solo vale por si se necesita descargar el dataset o algÃºn preprocesamiento muy temprano\n",
    "        Ãšnicamente se ejecuta una vez al principio del entrenamiento\n",
    "        \"\"\"\n",
    "        pass # descargar_dataset()\n",
    "\n",
    "    def setup(self, stage=None): # esta funciÃ³n la ejecuta el trainer cuando se va a ejecutar el fit o el predict\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = IrisDataset(self.train_df)\n",
    "            self.val_dataset = IrisDataset(self.val_df)\n",
    "\n",
    "        elif stage == 'test':\n",
    "            self.test_dataset = IrisDataset(self.test_df)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        features, targets = zip(*batch)\n",
    "        features = torch.tensor(np.stack(features), dtype=torch.float32)\n",
    "        targets = torch.tensor(targets, dtype=torch.long)\n",
    "        return features, targets\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
    "\n",
    "iris_df = pd.read_csv(IRIS_PATH)\n",
    "iris_data_module = IrisDataModule(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¿Por quÃ© nos da error si ya hemos instanciado el data module?\n",
    "\n",
    "AÃºn no hemos empezado a entrenar, por lo que internamente Lightning no ha ejecutado la funciÃ³n setup() del data_module\n",
    "En nuestro caso (iris) esto no es relevante, sin embargo, en el mundo real donde un split pueden ser, por ejemplo, cientos de GB\n",
    "de imÃ¡genes, tenerlas cargadas en memoria antes de entrenar puede ser innecesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IrisDataModule' object has no attribute 'train_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataloader = \u001b[43miris_data_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mIrisDataModule.train_dataloader\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataset\u001b[49m, batch_size=\u001b[38;5;28mself\u001b[39m.batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn=\u001b[38;5;28mself\u001b[39m.collate_fn)\n",
      "\u001b[31mAttributeError\u001b[39m: 'IrisDataModule' object has no attribute 'train_dataset'"
     ]
    }
   ],
   "source": [
    "train_dataloader = iris_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura y lÃ³gica de entrenamiento en un mismo mÃ³dulo (LightningModule y Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¿Acaso odias tener que preocuparte de **que estÃ¡ o no estÃ¡ en GPU**?\n",
    "\n",
    "Â¿Detestas **el bucle de entrenamiento** tan estÃ©ticamente horroroso que tenemos que hacer para entrenar con PyTorch?\n",
    "\n",
    "Â¿EstÃ¡s cansado de tener que preocuparte de **como y cada cuanto** loggear las mÃ©tricas?\n",
    "\n",
    "Si te sientes identificado, quizÃ¡s empieces a entender el potencial de PytorchLightning con su pieza de puzle bÃ¡sica, el LightningModule.\n",
    "\n",
    "A continuaciÃ³n vamos a realizar una comparativa entre como serÃ­a entrenar un simple MLP para el dataset iris con PyTorch versus con PyTorchLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape=4, n_classes=3):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.l1 = nn.Linear(self.input_shape, 64)\n",
    "        self.l2 = nn.Linear(64, self.n_classes)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.l1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "def compute_metrics(preds, targets, losses):\n",
    "    preds = torch.cat(preds).cpu().numpy()\n",
    "    targets = torch.cat(targets).cpu().numpy()\n",
    "\n",
    "    acc = (preds == targets).sum() / len(targets)\n",
    "    f1 = f1_score(targets, preds, average='macro')\n",
    "    loss = sum(losses) / len(losses)\n",
    "    return acc, f1, loss\n",
    "    \n",
    "def evaluate(loader, model, criterion, device='cpu'):\n",
    "    with torch.no_grad():\n",
    "        preds, targets, losses = [], [], []\n",
    "        for inputs, target in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "\n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return compute_metrics(preds, targets, losses)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=10, learning_rate=1e-3):\n",
    "    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = 'cpu'\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        preds, targets, losses = [], [], []\n",
    "        for inputs, target in train_loader:\n",
    "            inputs = inputs.to(device) # mandamos el inputs al mismo device (GPU) que el modelo\n",
    "\n",
    "            optimizer.zero_grad() # ponemos a cero los gradientes\n",
    "\n",
    "            output = model(inputs) # forward pass\n",
    "            pred = torch.argmax(output, dim=1) # obtenemos la clase predicha\n",
    "\n",
    "            loss = criterion(output, target) # calculamos la pÃ©rdida\n",
    "            loss.backward() # backpropagation\n",
    "\n",
    "            optimizer.step() # actualizamos los pesos\n",
    "\n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        train_acc, train_f1, train_loss = compute_metrics(preds, targets, losses)\n",
    "\n",
    "        model.eval()\n",
    "        val_acc, val_f1, val_loss = evaluate(val_loader, model, criterion, device=device)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.3f} - Train Acc: {train_acc:.3f} - Train F1: {train_f1:.3f} - Val Loss: {val_loss:.3f} - Val Acc: {val_acc:.3f} - Val F1: {val_f1:.3f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] - Train Loss: 1.691 - Train Acc: 0.344 - Train F1: 0.171 - Val Loss: 1.613 - Val Acc: 0.300 - Val F1: 0.154\n",
      "Epoch [2/30] - Train Loss: 1.410 - Train Acc: 0.344 - Train F1: 0.171 - Val Loss: 1.338 - Val Acc: 0.300 - Val F1: 0.154\n",
      "Epoch [3/30] - Train Loss: 1.176 - Train Acc: 0.344 - Train F1: 0.171 - Val Loss: 1.148 - Val Acc: 0.300 - Val F1: 0.154\n",
      "Epoch [4/30] - Train Loss: 1.056 - Train Acc: 0.400 - Train F1: 0.273 - Val Loss: 1.032 - Val Acc: 0.433 - Val F1: 0.362\n",
      "Epoch [5/30] - Train Loss: 0.984 - Train Acc: 0.578 - Train F1: 0.481 - Val Loss: 0.973 - Val Acc: 0.600 - Val F1: 0.516\n",
      "Epoch [6/30] - Train Loss: 0.946 - Train Acc: 0.733 - Train F1: 0.732 - Val Loss: 0.932 - Val Acc: 0.733 - Val F1: 0.681\n",
      "Epoch [7/30] - Train Loss: 0.908 - Train Acc: 0.767 - Train F1: 0.741 - Val Loss: 0.890 - Val Acc: 0.900 - Val F1: 0.900\n",
      "Epoch [8/30] - Train Loss: 0.859 - Train Acc: 0.756 - Train F1: 0.718 - Val Loss: 0.853 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [9/30] - Train Loss: 0.809 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.819 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [10/30] - Train Loss: 0.780 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.791 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [11/30] - Train Loss: 0.751 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.760 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [12/30] - Train Loss: 0.718 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.724 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [13/30] - Train Loss: 0.688 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.696 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [14/30] - Train Loss: 0.662 - Train Acc: 0.678 - Train F1: 0.560 - Val Loss: 0.667 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [15/30] - Train Loss: 0.631 - Train Acc: 0.700 - Train F1: 0.609 - Val Loss: 0.644 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [16/30] - Train Loss: 0.623 - Train Acc: 0.700 - Train F1: 0.609 - Val Loss: 0.627 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [17/30] - Train Loss: 0.596 - Train Acc: 0.711 - Train F1: 0.631 - Val Loss: 0.605 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [18/30] - Train Loss: 0.590 - Train Acc: 0.711 - Train F1: 0.631 - Val Loss: 0.595 - Val Acc: 0.633 - Val F1: 0.540\n",
      "Epoch [19/30] - Train Loss: 0.567 - Train Acc: 0.733 - Train F1: 0.672 - Val Loss: 0.572 - Val Acc: 0.767 - Val F1: 0.751\n",
      "Epoch [20/30] - Train Loss: 0.549 - Train Acc: 0.844 - Train F1: 0.833 - Val Loss: 0.554 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [21/30] - Train Loss: 0.539 - Train Acc: 0.822 - Train F1: 0.805 - Val Loss: 0.543 - Val Acc: 0.800 - Val F1: 0.792\n",
      "Epoch [22/30] - Train Loss: 0.535 - Train Acc: 0.800 - Train F1: 0.775 - Val Loss: 0.530 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [23/30] - Train Loss: 0.516 - Train Acc: 0.844 - Train F1: 0.833 - Val Loss: 0.516 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [24/30] - Train Loss: 0.499 - Train Acc: 0.889 - Train F1: 0.884 - Val Loss: 0.504 - Val Acc: 0.933 - Val F1: 0.933\n",
      "Epoch [25/30] - Train Loss: 0.496 - Train Acc: 0.856 - Train F1: 0.846 - Val Loss: 0.499 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [26/30] - Train Loss: 0.474 - Train Acc: 0.833 - Train F1: 0.819 - Val Loss: 0.487 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [27/30] - Train Loss: 0.469 - Train Acc: 0.844 - Train F1: 0.833 - Val Loss: 0.479 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [28/30] - Train Loss: 0.461 - Train Acc: 0.822 - Train F1: 0.805 - Val Loss: 0.469 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [29/30] - Train Loss: 0.446 - Train Acc: 0.856 - Train F1: 0.846 - Val Loss: 0.460 - Val Acc: 0.833 - Val F1: 0.829\n",
      "Epoch [30/30] - Train Loss: 0.435 - Train Acc: 0.889 - Train F1: 0.884 - Val Loss: 0.451 - Val Acc: 0.933 - Val F1: 0.933\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model = train(model, iris_train_loader, iris_val_loader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, en PyTorch, la lÃ³gica de entrenamiento estÃ¡ completamente separado de la arquitectura del modelo, asÃ­ como de como se realiza el forward pass.\n",
    "\n",
    "Veamos a continuaciÃ³n como implementar el mismo ejemplo en PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "class Classifier(pytorch_lightning.LightningModule):\n",
    "    def __init__(self, input_shape=4, n_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Inicializamos las capas de la red\n",
    "        self.l1 = nn.Linear(input_shape, 64)\n",
    "        self.l2 = nn.Linear(64, n_classes)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # FunciÃ³n de pÃ©rdida\n",
    "        self.criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "        # Inicializamos las mÃ©tricas\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=n_classes)\n",
    "        self.f1 = F1Score(task='multiclass', num_classes=n_classes)\n",
    "\n",
    "    # FunciÃ³n forward como en un nn.Module de PyTorch\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "    # Como computamos un batch del train_dataloader\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        output = self(inputs)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "\n",
    "        loss = self.criterion(output, targets)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                'train_loss': loss, \n",
    "                'train_acc': self.accuracy(preds, targets), \n",
    "                'train_f1': self.f1(preds, targets)\n",
    "            }, \n",
    "            prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Como computamos un batch del val_dataloader\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        output = self(inputs)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "\n",
    "        loss = self.criterion(output, targets)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                'val_loss': loss, \n",
    "                'val_acc': self.accuracy(preds, targets), \n",
    "                'val_f1': self.f1(preds, targets) \n",
    "            }, \n",
    "            prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Como computamos un batch del test_dataloader\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        output = self(inputs)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "\n",
    "        loss = self.criterion(output, targets)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                'test_loss': loss, \n",
    "                'test_acc': self.accuracy(preds, targets), \n",
    "                'test_f1': self.f1(preds, targets)\n",
    "            }, \n",
    "            prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # ConfiguraciÃ³n del optimizador\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3) # self.parameters() son los parÃ¡metros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | l1        | Linear             | 320    | train\n",
      "1 | l2        | Linear             | 195    | train\n",
      "2 | act       | ReLU               | 0      | train\n",
      "3 | criterion | CrossEntropyLoss   | 0      | train\n",
      "4 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "5 | f1        | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------\n",
      "515       Trainable params\n",
      "0         Non-trainable params\n",
      "515       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f307e014e464387aa7019297c06a073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0849af9622485390f57829de968938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd67358686c047f5ba88e9c0fabbb1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba54ecde4e744fa088ed230b793c2f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1f62915f3442885971b7cf86da7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92c63a7c8734a35b46f3f937a8e737f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20728b281f9b4f7192fb89ecdc7e21de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1be4f73967479e8ef1e66203db8e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88890deb35bd4995b4c868c52c8baa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec1a9f0ca5492dacef2f2b908c19f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2c946128cc4fc886f181a6f05d8d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6581fa313fab49c4a8e86ba713a287ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e00975536344268dbaeab8e086dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db27382fa0b4460e879cd5bb59f0540a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dbbc187e4a499f8f9a9cc307fdfbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e84a85da94dfa9d7433241c3818c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8177019e8f44db4a92a717f51f44bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d77ebb5fc2408ca0d37a7b975d40a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604625916b9841d189ed606eaf02fbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542028c50219483c80fa0097f597a893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef38b0174069484fa69c3df122e136cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacc8f18dd1b41e69da93cdc6fbf4169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feee26c2f2694637b6b9bd909fd6068c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308b2fb1550e43d2ae53e627d8dcd81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8965ef4f807e4674952f4f8dbeabae3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdde7cf8ecd4abca320fc87fe868664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1451497101144a2bc0ca51fe0aafb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25725e09c5ed4d73ae9213e081d57aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c07cdb785d044dabe77feb59dd73400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f14d5dfd6547e89ad11395aa58c785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc81f2751944874a91d52bdc26ccf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8689f02828a94bac8a2f2f0b55d2b135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbe8311644c4b34a2f37c2632a90e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.7333333492279053     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.7333333492279053     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.5482696890830994     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.7333333492279053    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.7333333492279053    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.5482696890830994    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5482696890830994,\n",
       "  'test_acc': 0.7333333492279053,\n",
       "  'test_f1': 0.7333333492279053}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "trainer = pytorch_lightning.Trainer(max_epochs=30, accelerator='cpu')\n",
    "\n",
    "trainer.fit(model, iris_data_module)\n",
    "trainer.test(model, iris_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones que Responden a Eventos - Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Lightning gestiona su \"bucle\" de entrenamiento de manera encapsulada. Nosotros Ãºnicamente debemos decirle como hace el forward pass nuestra arquitectura, como se computa el batch y como se calcula la funciÃ³n de pÃ©rdida.\n",
    "\n",
    "Esto no quiere decir que no tengamos acceso al resto de eventos que ocurren durante el entrenamiento...\n",
    "\n",
    "Â¿Y si quiero que al final de cada batch se ejecute cierta funciÃ³n?\n",
    "Â¿Y si quiero que cuando cada evaluaciÃ³n termine se almacenen los datos de cierta forma?\n",
    "\n",
    "Para esto, Lightning nos ofrece los **hooks**, funciones del LightningModule que el usuario puede sobreescribir para ejecutar cierto cÃ³digo arbitrario cuando se dÃ© ese determinado evento.\n",
    "\n",
    "Los **callbacks** agrupan ciertos de estos **hooks** para realizar cierta funcionalidad. En Lightning podemos crear nuestros propios Callbacks, sin embargo, ya tenemos una gran variedad ya implementados con los que vamos a poder, por ejemplo, guardar los pesos del mejor modelo en validaciÃ³n (que asumimos que ha sido la Ã©poca en la que se ha conseguido mejor convergencia). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning\n",
    "\n",
    "class MyPrintingCallback(pytorch_lightning.Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Yo me ejecuto CUANDO el entrenamiento EMPIEZA\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"Yo me ejecuto CUANDO el entrenamiento TERMINA\")\n",
    "    \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        if batch_idx % 2 == 0:\n",
    "            print(f\"Hola!, soy el batch {batch_idx}, soy par y acabo de terminar\")\n",
    "        elif batch_idx % 2 != 0:\n",
    "            print(f\"Hola!, soy el batch {batch_idx}, soy impar y acabo de terminar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | l1        | Linear             | 320    | train\n",
      "1 | l2        | Linear             | 195    | train\n",
      "2 | act       | ReLU               | 0      | train\n",
      "3 | criterion | CrossEntropyLoss   | 0      | train\n",
      "4 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "5 | f1        | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------\n",
      "515       Trainable params\n",
      "0         Non-trainable params\n",
      "515       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61acf053b744420fb3738987fc23ea62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo me ejecuto CUANDO el entrenamiento EMPIEZA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70c5990aef649919f590280fe753469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!, soy el batch 0, soy par y acabo de terminar\n",
      "Hola!, soy el batch 1, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 2, soy par y acabo de terminar\n",
      "Hola!, soy el batch 3, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 4, soy par y acabo de terminar\n",
      "Hola!, soy el batch 5, soy impar y acabo de terminar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b51dd12c0ff47a5b0b455470193643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!, soy el batch 0, soy par y acabo de terminar\n",
      "Hola!, soy el batch 1, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 2, soy par y acabo de terminar\n",
      "Hola!, soy el batch 3, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 4, soy par y acabo de terminar\n",
      "Hola!, soy el batch 5, soy impar y acabo de terminar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1348daf71f4c00aee5093dcc7fbec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!, soy el batch 0, soy par y acabo de terminar\n",
      "Hola!, soy el batch 1, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 2, soy par y acabo de terminar\n",
      "Hola!, soy el batch 3, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 4, soy par y acabo de terminar\n",
      "Hola!, soy el batch 5, soy impar y acabo de terminar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5db273c9984e5789aae546d1c5b492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!, soy el batch 0, soy par y acabo de terminar\n",
      "Hola!, soy el batch 1, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 2, soy par y acabo de terminar\n",
      "Hola!, soy el batch 3, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 4, soy par y acabo de terminar\n",
      "Hola!, soy el batch 5, soy impar y acabo de terminar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6105c2097df49e081c32cd163069a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!, soy el batch 0, soy par y acabo de terminar\n",
      "Hola!, soy el batch 1, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 2, soy par y acabo de terminar\n",
      "Hola!, soy el batch 3, soy impar y acabo de terminar\n",
      "Hola!, soy el batch 4, soy par y acabo de terminar\n",
      "Hola!, soy el batch 5, soy impar y acabo de terminar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bae7f810374f46870a3bc314e7afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo me ejecuto CUANDO el entrenamiento TERMINA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21efddb1f694a11a725dbee8e24a075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9186697602272034     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9186697602272034    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.9186697602272034, 'test_acc': 0.5, 'test_f1': 0.5}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(IRIS_PATH)\n",
    "data_module = IrisDataModule(data)\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "trainer = pytorch_lightning.Trainer(max_epochs=5, accelerator='cpu', callbacks=[MyPrintingCallback()])\n",
    "\n",
    "trainer.fit(model, iris_data_module)\n",
    "trainer.test(model, iris_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los que mÃ¡s vamos a utilizar son:\n",
    "- [EarlyStopping](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.EarlyStopping.html#lightning.pytorch.callbacks.EarlyStopping)\n",
    "- [ModelCheckpoint](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html#lightning.pytorch.callbacks.ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | l1        | Linear             | 320    | train\n",
      "1 | l2        | Linear             | 195    | train\n",
      "2 | act       | ReLU               | 0      | train\n",
      "3 | criterion | CrossEntropyLoss   | 0      | train\n",
      "4 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "5 | f1        | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------\n",
      "515       Trainable params\n",
      "0         Non-trainable params\n",
      "515       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f997a35e21c4ac6836da0bd52685b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f493f783bf5d435b9965ff7e4f3a31a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16749cc35cd248bda11ad926ec1ea5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452935ab2639461da880f955e84467a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08422a1524b4a89af038f3e3d198172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b29a7e443d41ed91758b1b142de40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc7d1d73f0d46419a186a0db72f57a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05ef7ce4ab24ae8b43d900029f1af37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb8a15e83384c69a41077c45bf41bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8de836f5c0f4fdaaa401ff1e8777eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecceab1fb1824a5dafdbe12e546ca4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c1918864a947f7ad7a2180dba8ec03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b01290878d4f5cab1fed34accc35a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9e37b4d83342c292027a5f6bf2a1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd24809fa158479bb6dc82199bee0a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d86d75a122421b962bdbd5fefd4dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1028b793da4112b5b1f5977c9dc77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74ba3f9ded6415997f53baded038ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf3ced2a6de442091fea6ee709d5f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5d275fc15d49a4b4a9f136f0aa25a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4199d2c2328e455ea241f8630b6f86f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c922f008c34430586bd9b8e2c9f9f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cd2dcfb1cf4edcbfff0d1113695748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069ae89a24c14440bcb87b693c5acae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c733573656a44179b4b5bfa37ba135c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f54d4d873274a7ab14172632f1fcbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9ca95412c64758a98399d5398f41bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0da819c13b64e27804077c18792da00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80484ed1aaa43dda571b65ecc0fe6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77680c494c504ae9b7664c77ea054174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ace52ebfdd4c30aed1f94c5c3d66af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57392da3a88f48389fb18cc75851d1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4934be1ce25346559340e5faff4f452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806d60afcae946168353bc87cc2e38b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef1427bd7be429e9e622f4c2bc8cffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b78c040692490698a871d17c496999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ead64ca96a479fabcdcf10a40dba1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312b60b859f345eca751372b420fb10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c01dd7144dd414096c399f2b8e3ce3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398c5a33fdee45cf8251deb77ba23ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e8892a56b4a3ab7f7201fe2f57650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef5b1404bd4dbb84b2b5f39483e6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c389496df245faba6bb28b9e645f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5844f7b93bf49c7a723418aa7bb2390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e66548306e4bbfae76fb01aa0b905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c187177e9f974347b3c010f72722776b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a06dd9e92f4e2bb794813c763dda84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46aa5415de641ccba04ad155e0ebbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb91b236134443c9dd13b97b6710c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf089a18b8644b4b37fd72cd41a80e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789ec4ccfc5d44e2bbace7f90cddb1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ee3280ea3f479791d7a64460f2b9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5518bbeab4f649f8b8585ae2cc052aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.38685664534568787    </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.38685664534568787   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.38685664534568787, 'test_acc': 1.0, 'test_f1': 1.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "# DataModule\n",
    "data = pd.read_csv(IRIS_PATH)\n",
    "data_module = IrisDataModule(data)\n",
    "\n",
    "# LightningModule\n",
    "model = Classifier()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_callback = pytorch_lightning.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # monitorizamos la pÃ©rdida en el conjunto de validaciÃ³n\n",
    "    mode='min', # queremos minimizar la pÃ©rdida\n",
    "    patience=3, # nÃºmero de epochs sin mejora antes de parar\n",
    "    min_delta=0.001, # diferencia mÃ­nima para considerar que hay mejora\n",
    "    verbose=False, # si queremos que muestre mensajes del estado del early stopping \n",
    ")\n",
    "model_checkpoint_callback = pytorch_lightning.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss', # monitorizamos la pÃ©rdida en el conjunto de validaciÃ³n\n",
    "    mode='min', # queremos minimizar la pÃ©rdida\n",
    "    save_top_k=1, # guardamos solo el mejor modelo\n",
    "    dirpath='lightning_logs/models/', # directorio donde se guardan los modelos\n",
    "    filename=f'best_model_{datetime.datetime.now()}' # nombre del archivo\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping_callback, model_checkpoint_callback]\n",
    "\n",
    "# Trainer\n",
    "trainer = pytorch_lightning.Trainer(max_epochs=50, accelerator='cpu', callbacks=callbacks)\n",
    "\n",
    "trainer.fit(model, iris_data_module)\n",
    "trainer.test(model, iris_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registro de MÃ©tricas AutomÃ¡tico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el logger por defecto de Lightning que nos guarda lo que aÃ±adamos al log en un CSV ([CSVLogger](https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.CSVLogger.html#lightning.pytorch.loggers.CSVLogger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /home/adrian/deep-learning-dlmasterupm/assignments/pytorch_basics/session_5/lightning_logs/iris/2025-11-18_09-35-31 exists and is not empty.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | l1        | Linear             | 320    | train\n",
      "1 | l2        | Linear             | 195    | train\n",
      "2 | act       | ReLU               | 0      | train\n",
      "3 | criterion | CrossEntropyLoss   | 0      | train\n",
      "4 | accuracy  | MulticlassAccuracy | 0      | train\n",
      "5 | f1        | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------\n",
      "515       Trainable params\n",
      "0         Non-trainable params\n",
      "515       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774c681486b74e9fb7c631bc810d9abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d863e287050e402bb549457a05ee4e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fa9fb5ee874442997bf7f82bf84ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365dbdb852164b7dadf328467fee3a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75355926a92d47ec939ef81273f1d028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96737e37f7b9440eb5c2db98aa82c296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0d59156a6c4bb3aaeb1f752a2a146e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9937565c9a740e99c88625c5bbeebb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed97aab434634fb899bdeb3e77fef0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ef981bcbf64904b57fa097111cddb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa01224d7c7a43a5987c2136767c9139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f8604d8ad499990c6d5e782fd6abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a3d9c62d67461b9903ddde8f775c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ed9ea6f23c4b239b24ca3d59b5b994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d8f6f2f9243d5861fced91b6512e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54be7020cd3a41929a69988fc542c38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7432dfbe7a54d71ae0f2b3d435d37d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7283bce2ca434427b064405c2985aacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03f70b75e5741018e81d92ea1914646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e147e58b4403a97f4661fc726d365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a646a819c54f0484e78d3e3aa2bd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3670b8b2ab944c90beabd7c302446f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2045463215604708ac26a987b1db6159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcfbc78ccf142a099edd6aa64259c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261666f03ec04a0385a742b1bd7c3043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd3068e4b564d58bca7f5c8239e4911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332b4a47c47745db8e4393f11fea2a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988ebf750390405987221989a8c226aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf63e838a841d18e390fa98f1be799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983572577cc649ca82263bdb7442954a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9823a9d1b3e94bc3a54783a586c2d6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b308de30124f76988334ed6d58d28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ad03f5e38246fea24f0eafdbac5811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d277793c7b643a5a0b346f05144e7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4a72c59c5f42699030400ba32d49a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67c38812d014dc1b14ce2c3823933fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78262e11eef04f53b8b302308b72a542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bca20119aa94f18b80e07f8d1266869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c170a5c0b824009970a52569bbc4e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efacad5380e64322b59e9915c20b0cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82c0b5c1fc247da962eceb4f17e67fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bbfd827b8e4950af0348da7d6a1b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f63d473c4e941e7b737caabbd17019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f26b76c74e41599f697cee16e185e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3dd586fe07490cba5edc172eeecebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d925412f398a44aa9ca8a0f9d9e936f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af436be9ab5d4dc8843e555dcf11d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84391cc13634a478d4eb568dccb8b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83694136cbaf48728943c600f4e18ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763ca09d27094c97b1cc6122638063f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c270560a46b48658a747750961c9ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28315d16571e44ecb7a97904e37025b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "/home/adrian/miniconda3/envs/synthetic-generation/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b9575f4fdf4d99ac00f11b06c08365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.3715880811214447     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.3715880811214447    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3715880811214447, 'test_acc': 1.0, 'test_f1': 1.0}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "MODEL_ID = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# DataModule\n",
    "data = pd.read_csv(IRIS_PATH)\n",
    "data_module = IrisDataModule(data)\n",
    "\n",
    "# LightningModule\n",
    "model = Classifier()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_callback = pytorch_lightning.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # monitorizamos la pÃ©rdida en el conjunto de validaciÃ³n\n",
    "    mode='min', # queremos minimizar la pÃ©rdida\n",
    "    patience=3, # nÃºmero de epochs sin mejora antes de parar\n",
    "    min_delta=0.001, # diferencia mÃ­nima para considerar que hay mejora\n",
    "    verbose=False, # si queremos que muestre mensajes del estado del early stopping \n",
    ")\n",
    "model_checkpoint_callback = pytorch_lightning.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss', # monitorizamos la pÃ©rdida en el conjunto de validaciÃ³n\n",
    "    mode='min', # queremos minimizar la pÃ©rdida\n",
    "    save_top_k=1, # guardamos solo el mejor modelo\n",
    "    dirpath=f'lightning_logs/iris/{MODEL_ID}/', # directorio donde se guardan los modelos\n",
    "    filename=f'best_model' # nombre del archivo\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping_callback, model_checkpoint_callback]\n",
    "\n",
    "# Loggers\n",
    "csv_logger = pytorch_lightning.loggers.CSVLogger(\n",
    "    save_dir=f'lightning_logs/iris/{MODEL_ID}/',\n",
    "    name='metrics',\n",
    "    version=None\n",
    ")\n",
    "\n",
    "loggers = [csv_logger] # se pueden poner varios loggers (mirar documentaciÃ³n)\n",
    "\n",
    "# Trainer\n",
    "trainer = pytorch_lightning.Trainer(max_epochs=50, accelerator='cpu', callbacks=callbacks, logger=loggers)\n",
    "\n",
    "trainer.fit(model, iris_data_module)\n",
    "trainer.test(model, iris_data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic-generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
